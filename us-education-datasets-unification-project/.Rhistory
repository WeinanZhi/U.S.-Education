plot(1:10, d, xlab = "Degree", ylab = "MSE", type = "l")
points(which.min(d), d[which.min(d)], cex = 10, pch = 20)
library(ISLR)
library(boot)
set.seed(1)
d = rep(NA, 10)
for (i in 1:10) {
prediction = glm(wage ~ poly(age, i), data = Wage)
d[i] = cv.glm(Wage, prediction, K = 10)$d[1]
}
plot(1:10, d, xlab = "Degree", ylab = "MSE", type = "l")
points(which.min(d), d[which.min(d)], cex = 5, pch = 20)
m1 = lm(wage ~ age, data = Wage)
m2 = lm(wage ~ poly(age, 2), data = Wage)
m3 = lm(wage ~ poly(age, 3), data = Wage)
m4 = lm(wage ~ poly(age, 4), data = Wage)
m5 = lm(wage ~ poly(age, 5), data = Wage)
anova(m1, m2, m3, m4, m5)
plot(wage ~ age, data = Wage, col = "darkgrey")
age = seq(from = range(Wage$age)[1], to = range(Wage$age)[2])
wage = predict(lm(wage ~ poly(age, 3), data = Wage), newdata = list(age = age))
lines(age, wage, col = "red", lwd = 2)
s = rep(NA, 10)
for (i in 2:10) {
Wage$ac = cut(Wage$age, i)
pred = glm(wage ~ ac, data = Wage)
s[i] = cv.glm(Wage, pred, K = 10)$delta[1]
}
plot(2:10, s[-1], xlab = "Cuts", ylab = "MSE", type = "l")
points(which.min(s), s[which.min(s)], cex = 5, pch = 20)
plot(wage ~ age, data = Wage, col = "darkgrey")
age = seq(from = range(Wage$age)[1], to = range(Wage$age)[2])
wage = predict(lm(wage ~ cut(age, 8), data = Wage), newdata = list(age = age))
lines(age, wage, col = "red", lwd = 2)
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(40,40), y = c(0,100))
text(x = 40, y = 108, labels = c("t1"), col = "red")
# t2: y = 75; (0, 75) (40, 75)
lines(x = c(0,40), y = c(75,75))
text(x = -8, y = 75, labels = c("t2"), col = "red")
# t3: x = 75; (75,0) (75, 100)
lines(x = c(75,75), y = c(0,100))
text(x = 75, y = 108, labels = c("t3"), col = "red")
# t4: x = 20; (20,0) (20, 75)
lines(x = c(20,20), y = c(0,75))
text(x = 20, y = 80, labels = c("t4"), col = "red")
# t5: y=25; (75,25) (100,25)
lines(x = c(75,100), y = c(25,25))
text(x = 70, y = 25, labels = c("t5"), col = "red")
text(x = (40+75)/2, y = 50, labels = c("R1"))
text(x = 20, y = (100+75)/2, labels = c("R2"))
text(x = (75+100)/2, y = (100+25)/2, labels = c("R3"))
text(x = (75+100)/2, y = 25/2, labels = c("R4"))
text(x = 30, y = 75/2, labels = c("R5"))
text(x = 10, y = 75/2, labels = c("R6"))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(10,40), y = c(10,100))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red", font = 5)
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red", font = 10)
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red", font = 100)
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
lines(x = c(70,70), y = c(0,100))
text(x = 70, y = 100, labels = c("cp2"), col = "red")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
lines(x = c(70,70), y = c(0,100))
text(x = 70, y = 100, labels = c("cp2"), col = "red")
lines(x = c(0,30), y = c(30,30))
text(x = 0, y = 30, labels = c("cp3"), col = "red")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
lines(x = c(70,70), y = c(0,100))
text(x = 70, y = 100, labels = c("cp2"), col = "red")
lines(x = c(0,30), y = c(30,30))
text(x = 0, y = 30, labels = c("cp3"), col = "red")
lines(x = c(30,70), y = c(50,50))
text(x = 30, y = 50, labels = c("cp4"), col = "red")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(0,100), ylim = c(0,100), xlab = "X", ylab = "Y")
lines(x = c(30,30), y = c(0,100))
text(x = 30, y = 100, labels = c("cp1"), col = "red")
lines(x = c(70,70), y = c(0,100))
text(x = 70, y = 100, labels = c("cp2"), col = "red")
lines(x = c(0,30), y = c(30,30))
text(x = 0, y = 30, labels = c("cp3"), col = "red")
lines(x = c(30,70), y = c(50,50))
text(x = 30, y = 50, labels = c("cp4"), col = "red")
lines(x = c(70,100), y = c(70,70))
text(x = 70, y = 70, labels = c("cp5"), col = "red")
text(x = (30+0)/2, y = (30+100)/2, labels = c("R1"))
text(x = (30+0)/2, y = (30+0)/2, labels = c("R2"))
text(x = (30+70)/2, y = (100+50)/2, labels = c("R3"))
text(x = (30+70)/2, y = (0+50)/2, labels = c("R4"))
text(x = (70+100)/2, y = (70+100)/2, labels = c("R5"))
text(x = (70+100)/2, y = (0+70)/2, labels = c("R6"))
library(ISLR)
set.seed(1)
subset = sample(1:nrow(Carseats), nrow(Carseats) / 2)
library(ISLR)
set.seed(1)
subset = sample(1:nrow(Carseats), nrow(Carseats) / 2)
library(ISLR)
set.seed(1)
train <- sample(1:nrow(Carseats), nrow(Carseats) / 2)
library(ISLR)
set.seed(1)
summary(Carseats)
library(ISLR)
set.seed(1)
train <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[train, ]
library(ISLR)
set.seed(1)
train <- sample(1:nrow(Carseats), nrow(Carseats) / 2)
library(ISLR)
class(ISLR::Carseats)
library(ISLR)
class(ISLR::Carseats)
head(ISLR::Carseats)
library(ISLR)
class(ISLR::Carseats)
head(ISLR::Carseats)
summary(ISLR::Carseats)
library(ISLR)
summary(ISLR::Carseats)
library(ISLR)
set.seed(1)
train <- sample(1:nrow(ISLR::Carseats), nrow(ISLR::Carseats) / 2)
Carseats.train <- Carseats[train, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(College), nrow(College)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
subset <- sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
Carseats.train <- Carseats[subset, ]
library(ISLR)
set.seed(1)
class(Carseats)
library(ISLR)
set.seed(1)
class(ISLR::Carseats)
library(ISLR)
set.seed(1)
ss = sample(nrow(Carseats), nrow(Carseats)*0.7)
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
train = Carseats[train,]
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
train = ISLR::Carseats[train,]
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.7)
train = ISLR::Carseats[ss,]
test = ISLR::Carseats[-ss,]
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.5)
train = ISLR::Carseats[ss,]
test = ISLR::Carseats[-ss,]
library(tree)
install.packages("tree")
library(tree)
rtree = tree(Sales~., data = train)
summary(rtree)
plot(rtree)
text(rtree)
Sales_hat = predict(rtree, newdata = test)
mean((Sales_hat - test$Sales)^2)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], col = "red", cex = 2, pch = 20)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 5, pch = 20)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 2, pch = 20)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 2, pch = 20)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 2, pch = 20)
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.5)
train = ISLR::Carseats[ss,]
test = ISLR::Carseats[-ss,]
library(tree)
rtree = tree(Sales~., data = train)
summary(rtree)
plot(rtree)
text(rtree)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 2, pch = 20)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 5, pch = 20)
library(ISLR)
set.seed(1)
ss = sample(nrow(ISLR::Carseats), nrow(ISLR::Carseats)*0.5)
train = ISLR::Carseats[ss,]
test = ISLR::Carseats[-ss,]
library(tree)
rtree = tree(Sales~., data = train)
summary(rtree)
plot(rtree)
text(rtree)
cv = cv.tree(rtree)
plot(cv$size, cv$dev, xlab = "size", ylab = "dev", type = "b")
points(which.min(cv$dev), cv$dev[which.min(cv$dev)], cex = 5, pch = 20)
pruned = prune.tree(rtree, best = 8)
plot(pruned)
text(pruned)
Sales_hat = predict(pruned, newdata = test)
mean((Sales_hat - test$Sales)^2)
bag = randomForest(Sales~., data = train, mtry = 10, ntree = 500, importance = TRUE)
install.packages("randomForest")
bag = randomForest(Sales~., data = train, mtry = 10, ntree = 500, importance = TRUE)
library(randomForest)
bag = randomForest(Sales~., data = train, mtry = 10, ntree = 500, importance = TRUE)
bag_pred = predict(bag, newdata = test)
mean((bag_pred - test$Sales)^2)
importance(bag)
rf = randomForest(Sales~., data = train, mtry = 3, ntree = 500, importance = TRUE)
rf_pred = predict(rf, newdata = test)
mean((rf_pred - test$Sales)^2)
importance(rf)
library(MASS)
library(leaps)
library(glmnet)
attach(Boston)
set.seed(1)
k = 5
folds = sample(1:k, nrow(Boston), replace = TRUE)
kfv_e = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))
for (i in 1:k) {
bss = regsubsets(crim~., data = Boston[folds != i, ], nvmax = 13)
for (j in 1:13) {
prediction = predict(bss, Boston[folds == i, ], id = j)
kfv_e[i, j] = mean((Boston$crim[folds == i] - prediction) ^ 2)
}
}
kfv_e_mean = apply(kfv_e, 2, mean)
plot(kfv_e_mean, xlab = "number of variables", ylab = "K-fold Cross Validation Error", type = "b")
#4.6.1 The Stock Market Data
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket)
cor(Smarket[,-9])
attach(Smarket)
plot(Volume)
plot(Volume)
#4.6.2 Logistic Regression
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
summary(glm.fits)
coef(glm.fits)
summary(glm.fits)$coef
glm.probs = predict(glm.fits, type = "response")
glm.probs[1:10]
glm.probs = predict(glm.fits, type = "response")
glm.probs = predict(glm.fits)
glm.probs[1:10]
glm.probs
glm.probs[1:10]
clear
glm.probs = predict(glm.fits, type = "response")
glm.probs[1:10]
constrasts(Direction)
contrasts(Direction)
glm.pred = rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
(507+145)/1250
mean(glm.pred == Direction)
train = (Year < 2005)
Smarket.2005 = Smarket[!train,]
dim(Smarktet.2005)
dim(Smarket.2005)
Direction.2005 = Direction[!train]
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket[train,], family = binomial)
glm.probs = predict(glm.fits, Smarket.2005, type="response")
glm.pred = rep["Down", 252]
glm.pred[glm.probs > .5] = "Up"
glm.pred = rep("Down", 252)
glm.pred[glm.probs > .5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
table(glm.pred, Direction)
glm.pred = rep("Down", 1250)
table(glm.pred, Direction)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
glm.probs = predict(glm.fits, type = "response")
glm.pred = rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
## second model with less predictors(p-value)
glm.fits = glm(Direction~Lag1+Lag2, data = Smarket, family = binomial, subset = train)
glm.probs = predict(glm.fits, Smarket.2005, type = "response")
## second model with less predictors(p-value)
glm.fits = glm(Direction~Lag1+Lag2, data = Smarket[train,], family = binomial)
glm.probs = predict(glm.fits, Smarket.2005, type = "response")
glm.pred = rep["Down", 252]
glm.pred = rep("Down", 252)
glm.pred[glm.probs > .5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred != Direction.2005)
predict(glm.fits,data.frame(Lag1=c(1.2,1.5), Lag2=c(1.1,-0.8)),type="response")
#4.6.3 LDA
library(ISLR)
#4.6.3 LDA
library(MASS)
lda.fit = lda(Direciton ~ Lag1 + Lag2, data = Smarket[train,])
#4.6.3 LDA
library(MASS)
lda.fit = lda(Direciton ~ Lag1 + Lag2, data = Smarket[train,])
attach(Smarket)
lda.fit = lda(Direciton ~ Lag1 + Lag2, data = Smarket[train,])
lda.fit = lda(Direction ~ Lag1 + Lag2, data = Smarket[train,])
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit, Smarket.2005)
lda.pred$class
lda.pred$posterior
lda.pred$class
lda.pred$x
lda.class = lda.pred$class
mean(lda.class != Direction.2005)
sum(lda.pred$posterior[,1] >= .5)
sum(lda.pred$posterior[,1] <.5)
lda.pred$posterior[1:20,1]
sum(lda.pred$posterior[,2] >=.5)
lda.class[1:20]
#4.6.4 QDA
qda.fit = qda(Direction ~ Lag1 + lag2, data = Smarket[train,])
#4.6.4 QDA
qda.fit = qda(Direction ~ Lag1 + Lag2, data = Smarket[train,])
qda.fit
qda.class = predict(qda.fit, Smarket.2005)
table(qda.class, Direction.2005)
table(qda.class ,Direction .2005)
table(qda.class ,Direction.2005)
table(qda.class, Direction.2005)
qda.class = predict(qda.fit, Smarket.2005)$class
table(qda.class, Direction.2005)
mean(qda.class != Direction.2005)
#4.6.5 KNN
library(class)
train.X = cbind(Lag1, Lag2)[train,]
test.X = cbind(Lag1, Lag2)[!train,]
train.Direction = Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.2005)
mean(knn.pred == Direction.2005)
knn.pred2 = knn(train.X, test.X, train.Direction, k = 3)
table(knn.pred2, Direction.2005)
mean(knn.pred2, Direction.2005)
mean(knn.pred2 == Direction.2005)
#4.6.6 Caravan Insurance Data
dim(Caravan)
attach(Caravan)
summary(Caravan)
summary(Purchase)
348/5822
standardized.X = scale(Caravan[,-86])
test = 1:1000
train.X = standardized.X[-test,]
test.X = standardized.X[test,]
train.Y = Purchase[-test,]
test.Y = Purchase[test,]
train.Y = Purchase[-test]
test.Y = Purchase[test]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Y, k = 1)
mean(test.Y != knn.pred)
table(knn.pred, test.Y)
9/(68+9)
9/(68+9)
## logistic regression
glm.fit = glm(Purchase~., data = Caravan[-test,], family = binomial)
glm.probs=predict(glm.fits,Caravan[test,],type="response")
## logistic regression
glm.fits = glm(Purchase~., data = Caravan[-test,], family = binomial)
glm.probs=predict(glm.fits,Caravan[test,],type="response")
glm.pred = rep("No", 1000)
glm.pred[glm.probs > .5] = "Yes"
table(glm.pred, test.Y)
glm.pred = rep("No", 1000)
glm.pred[glm.probs > .25] = "Yes"
table(glm.pred, test.Y)
11/(22+11)
#5.3.1 The Validation Set Approach
library(ISLR)
set.seed(1)
train = sample(392, 196)
lm.fit = lm(mpg~horsepower, data = Auto subset = train)
lm.fit = lm(mpg~horsepower, data = Auto, subset = train)
lm.fit = lm(mpg~horsepower, data = Auto[train,])
attach(Auto)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
#5.3.1 The Validation Set Approach
library(ISLR),
set.seed(1),
train = sample(392, 196),
lm.fit = lm(mpg~horsepower, data = Auto[train,]),
attach(Auto),
mean((mpg - predict(lm.fit, Auto))[-train]^2),
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/', echo=FALSE, warning=FALSE, message=FALSE)
setwd("~/2019spring/DS 502/Project/us-education-datasets-unification-project")
getwd()
Education = read.csv(file = "states_all.csv")
subset = 1:1200
train.X = Education[subset,]
test.X = Education[-subset,]
#plot(Education$YEAR, Education$AVG_MATH_4_SCORE, data = Education)
#summary(Education)
unique(Education$YEAR)
if ()
#6.5.1 Subset selection
library(ISLR)
#6.5.1 Subset selection
library(ISLR)
fix(Hitters)
